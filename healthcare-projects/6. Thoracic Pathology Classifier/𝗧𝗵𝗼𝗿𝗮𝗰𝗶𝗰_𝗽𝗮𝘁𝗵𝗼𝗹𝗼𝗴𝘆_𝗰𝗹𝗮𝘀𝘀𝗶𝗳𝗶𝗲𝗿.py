# -*- coding: utf-8 -*-
"""ð—§ð—µð—¼ð—¿ð—®ð—°ð—¶ð—°_ð—½ð—®ð˜ð—µð—¼ð—¹ð—¼ð—´ð˜†_ð—°ð—¹ð—®ð˜€ð˜€ð—¶ð—³ð—¶ð—²ð—¿.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eIZqxh6HmZi52NH7etR3PMoipqq01FlX

# NIH CXR8 Classification Tutorial
## Estimated completion time: 30 minutes
Process into five steps:
1. Defining a problem: what do we want our model to look for? For this we'll need to think of pathology we might find in a chest x-ray.
2. Data preparation: we'll talk about how to manipulate our data in a way the classification model can understand.
3. Training a model: we'll use a technology called TensorFlow to create our model.
4. Evaluating model performace: we'll talk about some important considerations when creating a model like this.
5. Deployment: we'll send our model to a website where we can then test it in the wild and send to others.

## i. Using Google Colab
This demonstration will take place in Google Colab. Please first sign in with your Google account, and click File -> Save a copy in Drive.

When you get into the draft environment, please ensure that you see "GPU on" and "Internet on" under Settings so you can utilize the cloud GPU for faster model training.

In this Notebook editing environment, each block of text is referred to as a cell. Cells containing formatted text are Markdown cells, as they use the Markdown formatting language. Similarly, cells containing code are code cells.

Clicking within a cell will allow you to edit the content of that cell (a.k.a. enter edit mode). You can also navigate between cells with the arrow keys. Note that the appearance of Markdown cells will change when you enter edit mode.

You can run code cells (and format Markdown cells) as you go along by clicking within the cell and then clicking the blue button with one arrow next to the cell or at the bottom of the window. You can also use the keyboard shortcut SHIFT + ENTER (press both keys at the same time).

Let's try this out by running the cell below. This will help us load the technologies we need to power our model.
"""

# Commented out IPython magic to ensure Python compatibility.
import sklearn.metrics # Used for evaluating model performance, e.g., accuracy, precision, recall.
import random # Provides functions for generating random numbers and choices.
import tensorflow as tf # Core library for building and training machine learning models.
import matplotlib.pyplot as plt # Used for creating static, animated, and interactive visualizations in Python.
import os # Provides a way of using operating system dependent functionality like reading or writing files.
import io # Tools for working with I/O streams.
import glob # Finds all the pathnames matching a specified pattern.
import scipy.misc # (Deprecated) Contains functions for tasks like image manipulation.
import numpy as np # Fundamental package for scientific computing with Python; used for array operations.
import pandas as pd # Used for data manipulation and analysis, especially with tabular data.
from six import BytesIO # Provides utilities for compatibility between Python 2 and 3, BytesIO for in-memory binary streams.
from PIL import Image, ImageDraw, ImageFont # Pillow library, used for opening, manipulating, and saving many different image file formats.
import shutil # Offers high-level file operations, like copying and removing files and directories.
from tensorflow.keras.applications.inception_v3 import InceptionV3 # Pre-trained InceptionV3 model from Keras applications.
from tensorflow.keras import layers # Used for building neural network layers.
from tensorflow.keras import Model # Used to define a Keras model.
import matplotlib # The whole Matplotlib library, useful for general plotting.
from tensorflow.keras.optimizers import RMSprop # An optimizer for neural networks.
import zipfile # For working with ZIP archives.
from tensorflow.keras.preprocessing.image import ImageDataGenerator # Used for real-time data augmentation on images.
import matplotlib.image as mpimg # Used for reading and displaying images.
from matplotlib.ticker import FormatStrFormatter # Used for formatting tick labels in plots.
from tensorflow.keras.utils import plot_model # Used for plotting the architecture of a Keras model.


LEARNING_RATE = 0.0001
repo_url = 'https://github.com/adleberg/medical-ai'
IMAGE_HEIGHT, IMAGE_WIDTH = 299, 299

def load_image_into_numpy_array(image):
    image = image.convert('RGB')
    (im_width, im_height) = image.size
    return np.array(image.getdata()).reshape(
        (im_height, im_width, 3)).astype(np.uint8)

print("Welcome! Downloading some things... this will take a minute.")

# %cd -q /content
repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))
!git clone {repo_url} --quiet
# %cd -q {repo_dir_path}
!git pull -q

!apt-get install graphviz -y
!pip install pydot

print("Great! You clicked on it correctly. Now let's get started.")

"""## 1. Defining a Problem
Let's start by thinking of something we can look for in a chest xray. Once we think of something, let's type it in below, in between the quotes `""`, and run the cell. I'll put in "`atelectasis`" by default, but let's see if we can think of something else.

We'll be using a subset of the [NIH CXR8 dataset](https://openaccess.thecvf.com/content_cvpr_2017/papers/Wang_ChestX-ray8_Hospital-Scale_Chest_CVPR_2017_paper.pdf) for this project but this principles here apply to any project. The NIH CXR8 dataset only has a few selected findings within its dataset, but let's pretend that we're creating a dataset from scratch (using Montage, e.g.). Of note, this dataset also has bounding boxes available to us for another demonstration on object detection.

We'll need to see how many examples there are of the finding we typed in. Let's run the cell below to see.

![Screenshot 2026-02-10 alle 6.20.42â€¯PM.png](data:image/png;base64,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)

Above are the labels we have available to us in this dataset.
"""

finding = "Cardiomegaly"
finding = finding.capitalize()

df = pd.read_csv("/content/medical-ai/labels.csv")
df.head()

positives = df.loc[df["label"] == finding]
negatives = df.loc[df["label"] == "No Finding"]
n = len(positives)

if n == 0:
  print("No studies found! Maybe check your spelling?")
  assert (n > 0)

TRAIN_RATIO = 0.8
TEST_RATIO = 0.2
n = len(positives)
TRAIN_N = int(n*TRAIN_RATIO)
TEST_N = int(n*TEST_RATIO)
print(TRAIN_N, TEST_N)

train_labels = pd.concat([positives[:TRAIN_N], negatives[:TRAIN_N]])
test_labels = pd.concat([positives[TRAIN_N:], negatives[TRAIN_N:n]])

"""## 2. Preparing the Data
Now, we've figured out what we want our model to take a look at. Behind the scenes, we just need to sort the data into two folders: one with negative cases and one with positive cases.
"""

rootdir = "/content/medical-ai/images/"
os.makedirs(rootdir+finding+"/test/positive",  exist_ok=True)
os.makedirs(rootdir+finding+"/test/negative",  exist_ok=True)
os.makedirs(rootdir+finding+"/train/positive", exist_ok=True)
os.makedirs(rootdir+finding+"/train/negative", exist_ok=True)

# copy images to new directories for training purposes
for idx, image in positives[:TRAIN_N].iterrows():
  source = rootdir+image["filename"]
  dst = rootdir+finding+"/train/positive/"+image["filename"]
  shutil.copy(source, dst)

for idx, image in positives[TRAIN_N:].iterrows():
  source = rootdir+image["filename"]
  dst = rootdir+finding+"/test/positive/"+image["filename"]
  shutil.copy(source, dst)

for idx, image in negatives[:TRAIN_N].iterrows():
  source = rootdir+image["filename"]
  dst = rootdir+finding+"/train/negative/"+image["filename"]
  shutil.copy(source, dst)

for idx, image in negatives[TRAIN_N:n].iterrows():
  source = rootdir+image["filename"]
  dst = rootdir+finding+"/test/negative/"+image["filename"]
  shutil.copy(source, dst)

print("Done moving "+str(n*2)+" images to positive and negative folders.")

from PIL import Image, ImageDraw, ImageFont

# load images into memory for visualization
positive_imgs, negative_imgs = [], []
IMAGE_HEIGHT, IMAGE_WIDTH = 299, 299

for idx, row in positives[:6].iterrows():
  image_path = rootdir+row["filename"]
  image = Image.open(image_path).resize((IMAGE_WIDTH, IMAGE_HEIGHT))
  positive_imgs.append(load_image_into_numpy_array(image))

for idx, row in negatives[:6].iterrows():
  image_path = rootdir+row["filename"]
  image = Image.open(image_path).resize((IMAGE_WIDTH, IMAGE_HEIGHT))
  negative_imgs.append(load_image_into_numpy_array(image))

for idx, img in enumerate(positive_imgs[:6]):
  plt.subplot(2, 3, idx+1)
  plt.title(finding)
  plt.imshow(positive_imgs[idx])
plt.show()

for idx, img in enumerate(negative_imgs[:6]):
  plt.subplot(2, 3, idx+1)
  plt.title("No Findings")
  plt.imshow(negative_imgs[idx])
plt.show()

"""## 3. Running the Model
In this section, we'll set up our chest X-ray image classification model using a technique called transfer learning with the [InceptionV3](https://arxiv.org/abs/1512.00567v3) architecture. This means we'll use an existing model that has already learned to classify images and adapt it to work with our own set of chest X-rays.

Building a good model to classify medical images from scratch requires a large amount of data. To overcome this challenge, we can use a pre-trained model that has been trained on a large dataset of general images. For example, the InceptionV3 model has been trained on [ImageNet](https://www.image-net.org/), which contains over 1.4 million images across 1,000 different categories. While these categories are not medical images, the model has learned to recognize many visual featuresâ€”such as edges, textures, and shapesâ€”that are also present in chest X-rays.
"""

pre_trained_model = InceptionV3(input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 3), weights="imagenet", include_top=False)

for layer in pre_trained_model.layers:
  layer.trainable = False

last_layer = pre_trained_model.get_layer('mixed7')
last_output = last_layer.output

x = tf.keras.layers.Flatten()(last_output)
x = tf.keras.layers.Dense(1024, activation='relu')(x)
x = tf.keras.layers.Dropout(0.2)(x)
x = tf.keras.layers.Dense(1, activation='sigmoid')(x)

model = Model(pre_trained_model.input, x)
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])

# Define our example directories and files
base_dir = rootdir = "/content/medical-ai/images/"
train_dir = os.path.join(base_dir, finding, 'train')
test_dir = os.path.join(base_dir, finding, 'test')

train_pos_dir = os.path.join(train_dir, 'positive')
train_neg_dir = os.path.join(train_dir, 'negative')
test_pos_dir = os.path.join(test_dir, 'positive')
test_neg_dir = os.path.join(test_dir, 'negative')

BATCH_SIZE = 64
IMG_SIZE = (299, 299)
IMG_SHAPE = IMG_SIZE + (3,)
train_dataset = tf.keras.utils.image_dataset_from_directory(train_dir, shuffle=True, batch_size=BATCH_SIZE, image_size=IMG_SIZE)
validation_dataset = tf.keras.utils.image_dataset_from_directory(test_dir, shuffle=True, batch_size=BATCH_SIZE, image_size=IMG_SIZE)

"""## 3.1 Define the Base Model
We use the InceptionV3 model pre-trained on the ImageNet dataset as our base model.
"""

# Define the base model using InceptionV3
base_model = tf.keras.applications.InceptionV3(
    input_shape=IMG_SHAPE,
    include_top=False,  # Exclude the final classification layer
    weights='imagenet'  # Load weights pre-trained on ImageNet
)

# Freeze the base model to keep the pre-trained weights unchanged
base_model.trainable = False

"""## 3.2 Data Augmentation
Here, we put it together.

We compile the model, telling it to focus on 'accuracy' as the evaluation metric.
"""

data_augmentation = tf.keras.Sequential([
  tf.keras.layers.RandomFlip("horizontal"),
  tf.keras.layers.RandomRotation(0.2),
  tf.keras.layers.RandomZoom(0.2),
])

inputs = tf.keras.Input(shape=IMG_SHAPE)
x = data_augmentation(inputs) # Apply data augmentation
x = tf.keras.applications.inception_v3.preprocess_input(x)
x = base_model(x, training=False)
x = tf.keras.layers.GlobalAveragePooling2D()(x)
x = tf.keras.layers.Dropout(0.5)(x)
outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)

# Define the complete model
model = tf.keras.Model(inputs, outputs)

# Compile the model with appropriate optimizer, loss function, and metrics
model.compile(
    optimizer=tf.keras.optimizers.Adam(),
    loss='binary_crossentropy',
    metrics=['accuracy']
)

"""## 3.4 Define Callbacks
Early stopping helps us to prevent overfitting (memorizing the data) by halting training when the validation loss stops improving.
"""

# Define early stopping callback to stop training when validation loss doesn't improve
early_stopping = tf.keras.callbacks.EarlyStopping(
    monitor='val_loss',           # Monitor validation loss
    patience=5,                   # Number of epochs with no improvement after which training will be stopped
    restore_best_weights=True     # Restore model weights from the epoch with the best value of the monitored quantity
)

"""## 4. Train the Model
Finally, let's train the model using the features we extracted. We'll train on all 80% of the labels we have, and verify their accuracy on the remaining 20%.
"""

# Set the number of epochs for initial training
initial_epochs = 40

# Train the model with early stopping
history = model.fit(
    train_dataset,
    epochs=initial_epochs,
    validation_data=validation_dataset,
    callbacks=[early_stopping]
)

"""## 4.1 Fine-Tune the Model
Right now, our model is sort of smart. We'll change the learning rate so it doesn't jump to conclusions too quickly.
"""

base_model.trainable = True
fine_tune_at = 249 # specific to this architecture

# Freeze all layers before the fine_tune_at layer
for layer in base_model.layers[:fine_tune_at]:
    layer.trainable = False

# Recompile the model with a lower learning rate
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),
    loss='binary_crossentropy',
    metrics=['accuracy']
)

# Set the number of epochs for fine-tuning
fine_tune_epochs = 40
total_epochs = initial_epochs + fine_tune_epochs  # Total epochs

# Continue training the model with fine-tuning
history_fine = model.fit(
    train_dataset,
    epochs=total_epochs,
    initial_epoch=history.epoch[-1],  # Start from the last epoch of initial training
    validation_data=validation_dataset,
    callbacks=[early_stopping]  # Use early stopping
)

"""## 4.2 Plotting the progress
Let's plot the training and test loss and accuracy to show it conclusively:
"""

# Combine histories
acc = history.history['accuracy'] + history_fine.history['accuracy']
val_acc = history.history['val_accuracy'] + history_fine.history['val_accuracy']
loss = history.history['loss'] + history_fine.history['loss']
val_loss = history.history['val_loss'] + history_fine.history['val_loss']

# Total epochs
total_epochs = len(acc)
fine_tune_start = initial_epochs  # Epoch where fine-tuning starts

plt.figure(figsize=(10, 10))

# Accuracy plot
plt.subplot(2, 1, 1)
plt.plot(range(total_epochs), acc, label='Training Accuracy')
plt.plot(range(total_epochs), val_acc, label='Validation Accuracy')
plt.axvline(x=fine_tune_start, color='r', linestyle='--', label='Fine-Tuning Start')
plt.legend(loc='lower right')
plt.ylabel('Accuracy')
plt.ylim([0, 1])
plt.title('Training and Validation Accuracy')

# Loss plot
plt.subplot(2, 1, 2)
plt.plot(range(total_epochs), loss, label='Training Loss')
plt.plot(range(total_epochs), val_loss, label='Validation Loss')
plt.axvline(x=fine_tune_start, color='r', linestyle='--', label='Fine-Tuning Start')
plt.legend(loc='upper right')
plt.ylabel('Cross Entropy Loss')
plt.ylim([0, max(max(loss), max(val_loss))])
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')

plt.tight_layout()
plt.show()

"""## 5. Evaluating Performance
In this section we will investigate how it works on different parts.
"""

def predict_image(filename):
  image = Image.open(filename).resize((IMAGE_HEIGHT, IMAGE_WIDTH))
  image_np = load_image_into_numpy_array(image)
  expanded = np.expand_dims(image_np, axis=0)
  return model.predict(expanded)[0][0]

def show_df_row(row):
  image_path = row["filepath"]
  image = Image.open(image_path).resize((IMAGE_WIDTH, IMAGE_HEIGHT))
  img = load_image_into_numpy_array(image)
  expanded = np.expand_dims(img, axis=0)
  pred = model.predict(expanded)[0][0]
  guess = "neg"
  if pred > 0.5:
    guess = "pos"
  title = "Image: "+row["filename"]+" Label: "+row["label"]+" Guess: "+guess+" Score: "+str(pred)
  plt.title(title)
  plt.imshow(img)
  plt.show()
  return

results = []
for image in os.listdir(test_neg_dir):
  filename = test_neg_dir+"/"+image
  confidence = predict_image(filename)
  guess = 'pos' if confidence > 0.5 else 'neg'
  results.append([filename, image, "neg", guess, confidence])

for image in os.listdir(test_pos_dir):
  filename = test_pos_dir+"/"+image
  confidence = predict_image(filename)
  guess = 'pos' if confidence > 0.5 else 'neg'
  results.append([filename, image, "pos", guess, confidence])

sorted_results = sorted(results, key=lambda x: x[4], reverse=True)
df = pd.DataFrame(data=sorted_results, columns=["filepath","filename","label","guess","confidence"])

print("Done inference!")

df.head()

"""## 5.1 Example image"""

import random
n = random.randint(0, len(df)-1)
show_df_row(df.iloc[n])

"""## 5.2 Show Table of images"""

df[::5][['filename', 'label',"guess","confidence"]]

"""## 5.3 Show Histogram"""

pos = df.loc[df['label'] == "pos"]["confidence"]
neg = df.loc[df['label'] == "neg"]["confidence"]
fig, ax = plt.subplots()
n, bins, patches = plt.hist([pos,neg], np.arange(0.0, 1.1, 0.1).tolist(), edgecolor='black', linewidth=0.5, density=False, histtype='bar', stacked=True, color=['green', 'red'], label=[finding, 'Negative'])
plt.xlabel('Confidence')
plt.ylabel('N')
plt.xticks(bins)
ax.xaxis.set_major_formatter(FormatStrFormatter('%.2f'))
plt.title('Confidence scores for different values')
plt.legend(loc="lower right", fontsize=16)
plt.show()

"""## 5.4 Create cutoff point

"""

cutoff = 0.79 #@param {type:"slider", min:0, max:1, step:0.01}

def create_with_cutoff(cutoff):
    __, ax = plt.subplots(figsize=(12, 8))  # Increased figure size
    TP = df.loc[(df['label'] == "pos") & (df["confidence"] > cutoff)]["confidence"]
    FP = df.loc[(df['label'] == "neg") & (df["confidence"] > cutoff)]["confidence"]
    FN = df.loc[(df['label'] == "pos") & (df["confidence"] < cutoff)]["confidence"]
    TN = df.loc[(df['label'] == "neg") & (df["confidence"] < cutoff)]["confidence"]

    # Plot the histogram
    plt.hist([TP, FP, TN, FN], bins=np.arange(0.0, 1.1, 0.1).tolist(),
             edgecolor='black', linewidth=0.5, density=False, histtype='bar',
             stacked=True, color=['limegreen', 'forestgreen', 'orangered', 'salmon'],
             label=['TP', 'FP', 'TN', 'FN'])

    plt.xlabel('Confidence', fontsize=16)
    plt.ylabel('N', fontsize=16)
    plt.xticks(np.arange(0.0, 1.1, 0.1), fontsize=14)
    plt.yticks(fontsize=14)
    ax.xaxis.set_major_formatter(FormatStrFormatter('%.2f'))
    plt.title('Confidence scores for different values', fontsize=18)
    plt.axvline(cutoff, color='k', linestyle='dashed', linewidth=2)
    plt.legend(loc="upper right", fontsize=14)  # Adjusted legend location to avoid overlap

    # Calculate statistics
    sens = round(len(TP) / (len(TP) + len(FN)), 2)
    spec = round(len(TN) / (len(TN) + len(FP)), 2)
    stats = f"sensitivity: {sens}\nspecificity: {spec}\n\nTP: {len(TP)}\nFP: {len(FP)}\nTN: {len(TN)}\nFN: {len(FN)}"

    # Display stats in a box to make it more readable
    plt.text(0.75, 0.35, stats, fontsize=14, transform=ax.transAxes,
             bbox=dict(facecolor='white', alpha=0.8, edgecolor='black'))

    plt.show()

create_with_cutoff(cutoff)

"""## 5.5 Show ROC Curve"""

def create_auc_curve(classifications):
  squares = {}
  for x in classifications:
    conf = x[4]
    TP, FP, TN, FN = 0, 0, 0, 0
    for row in classifications:
      assert (row[2] == "neg" or row[2] == "pos")
      if row[2] == "neg":
        if float(row[4]) < conf: TN += 1
        else: FP += 1
      else:
        if float(row[4]) > conf: TP += 1
        else: FN += 1
    squares[conf] = [TP, FP, TN, FN]
  # now we have a list of stuff: convert to
  sens_spec = {}
  for entry in squares:
    sens = squares[entry][0] / float(squares[entry][0] + squares[entry][3])
    spec = squares[entry][2] / float(squares[entry][2] + squares[entry][1])
    sens_spec[entry] = (1-spec, sens)
  return squares, sens_spec

squares, sens_spec = create_auc_curve(sorted_results)

x = []
y = []
for point in sens_spec.keys():
  x.append(sens_spec[point][0])
  y.append(sens_spec[point][1])

auc = sklearn.metrics.auc(x, y)

plt.figure()
lw = 2
plt.plot(x, y, color='darkorange', lw=lw, label='ROC curve (area = %0.3f)' % auc)
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.ylabel('Sensitivity')
plt.xlabel('1-specificity')
plt.title('Receiver operating characteristic')
plt.legend(loc="lower right", fontsize=20)
plt.show()

"""5.6 Save Model"""

model.export('/content/export/'+finding)
!zip -r /content/{finding}.zip /content/export/{finding}